{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes\n",
    "\n",
    "***Definition***\n",
    "\n",
    "Naïve Bayes algorithm is a supervised learning algorithm, which is based on Bayes theorem and used for solving classification problems.\n",
    "It is mainly used in text classification that includes a high-dimensional training dataset.\n",
    "Naïve Bayes Classifier is one of the simple and most effective Classification algorithms which helps in building the fast machine learning models that can make quick predictions.\n",
    "It is a probabilistic classifier, which means it predicts on the basis of the probability of an object.\n",
    "Some popular examples of Naïve Bayes Algorithm are spam filtration, Sentimental analysis, and classifying articles.\n",
    "Why is it called Naïve Bayes?\n",
    "The Naïve Bayes algorithm is comprised of two words Naïve and Bayes, Which can be described as:\n",
    "\n",
    "Naïve: It is called Naïve because it assumes that the occurrence of a certain feature is independent of the occurrence of other features. Such as if the fruit is identified on the bases of color, shape, and taste, then red, spherical, and sweet fruit is recognized as an apple. Hence each feature individually contributes to identify that it is an apple without depending on each other.\n",
    "Bayes: It is called Bayes because it depends on the principle of Bayes' Theorem.\n",
    "Bayes' Theorem:\n",
    "Bayes' theorem is also known as Bayes' Rule or Bayes' law, which is used to determine the probability of a hypothesis with prior knowledge. It depends on the conditional probability.\n",
    "The formula for Bayes' theorem is given as:\n",
    "\n",
    "Naïve Bayes Classifier Algorithm where,\n",
    "\n",
    "P(A|B) is Posterior probability: Probability of hypothesis A on the observed event B.\n",
    "\n",
    "P(B|A) is Likelihood probability: Probability of the evidence given that the probability of a hypothesis is true.\n",
    "\n",
    "P(A) is Prior Probability: Probability of hypothesis before observing the evidence.\n",
    "\n",
    "P(B) is Marginal Probability: Probability of Evidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For instance we'll play around with dummy data\n",
    "import numpy as np\n",
    "weather=['Sunny','Sunny','Overcast','Rainy','Rainy','Rainy','Overcast','Sunny','Sunny',\n",
    "'Rainy','Sunny','Overcast','Overcast','Rainy']\n",
    "temp=['Hot','Hot','Hot','Mild','Cool','Cool','Cool','Mild','Cool','Mild','Mild','Mild','Hot','Mild']\n",
    "\n",
    "play=['No','No','Yes','Yes','Yes','No','Yes','No','Yes','Yes','Yes','Yes','Yes','No']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 2 0 1 1 1 0 2 2 1 2 0 0 1]\n"
     ]
    }
   ],
   "source": [
    "# Import LabelEncoder\n",
    "from sklearn import preprocessing\n",
    "import numpy as np\n",
    "\n",
    "#creating labelEncoder\n",
    "le = preprocessing.LabelEncoder()\n",
    "\n",
    "# Converting string labels into numbers.\n",
    "weather_encoded=le.fit_transform(weather)\n",
    "print (weather_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temp: [1 1 1 2 0 0 0 2 0 2 2 2 1 2]\n",
      "Play: [0 0 1 1 1 0 1 0 1 1 1 1 1 0]\n"
     ]
    }
   ],
   "source": [
    "# Converting string labels into numbers\n",
    "temp_encoded=le.fit_transform(temp)\n",
    "label=le.fit_transform(play)\n",
    "print (\"Temp:\",temp_encoded)\n",
    "print (\"Play:\",label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Value: [1]\n"
     ]
    }
   ],
   "source": [
    "#Combining weather and temp into single list of tuples\n",
    "features=list(zip(weather_encoded,temp_encoded))\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "#Create a Gaussian Classifier\n",
    "model = GaussianNB()\n",
    "\n",
    "# Train the model using the training sets\n",
    "model.fit(features,label)\n",
    "\n",
    "#Predict Output\n",
    "predicted= model.predict([[0,2]]) # 0:Overcast, 2:Mild\n",
    "print (\"Predicted Value:\", predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Let's try now with real world data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features:  ['alcohol', 'malic_acid', 'ash', 'alcalinity_of_ash', 'magnesium', 'total_phenols', 'flavanoids', 'nonflavanoid_phenols', 'proanthocyanins', 'color_intensity', 'hue', 'od280/od315_of_diluted_wines', 'proline']\n",
      "Labels:  ['class_0' 'class_1' 'class_2']\n"
     ]
    }
   ],
   "source": [
    "#Import scikit-learn dataset library\n",
    "from sklearn import datasets\n",
    "\n",
    "#Load dataset\n",
    "wine = datasets.load_wine()\n",
    "\n",
    "# print the names of the 13 features\n",
    "print (\"Features: \", wine.feature_names)\n",
    "\n",
    "# print the label type of wine(class_0, class_1, class_2)\n",
    "print (\"Labels: \", wine.target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import train_test_split function\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split dataset into training set and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(wine.data, wine.target, test_size=0.3,random_state=109)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Gaussian Naive Bayes model\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "#Create a Gaussian Classifier\n",
    "gnb = GaussianNB()\n",
    "\n",
    "#Train the model using the training sets\n",
    "gnb.fit(X_train, y_train)\n",
    "\n",
    "#Predict the response for test dataset\n",
    "y_pred = gnb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9074074074074074\n"
     ]
    }
   ],
   "source": [
    "#Import scikit-learn metrics module for accuracy calculation\n",
    "from sklearn import metrics\n",
    "\n",
    "# Model Accuracy, how often is the classifier correct?\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
